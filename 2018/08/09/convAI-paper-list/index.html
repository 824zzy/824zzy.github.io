<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta name="baidu-site-verification" content="UqlC4pwKIm" />
  <meta name="baidu-site-verification" content="d3U0dGeqGw" />
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">
  <script>
    (function () {
        if ('') {
            if (prompt('请输入文章密码') !== '') {
                alert('密码错误！');
                if (history.length === 1) {
                    location.replace("http://xxxxxxx.xxx"); // 这里替换成你的首页
                } else {
                    history.back();
                }
            }
        }
    })();
  </script>







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="1C1XSuJ8TgM2O0mcZvsgzEdy0IdRZOJfxDYPyh18U9Q" />














  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.cat.net/css?family=Roboto Slab:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="chatbot,conversationalAI,nlp,paper," />





  <link rel="alternate" href="/atom.xml" title="Zhengyuan Zhu" type="application/atom+xml" />






<meta name="description" content="论文列表格式&amp;emsp;论文发表年份： 论文题目&amp;论文链接：第一作者（第一作者所属学校&#x2F;机构），代码链接  OverviewExisting Models of Dialog SystemTask-Oriented Dialog 13: POMDP-Based Statistical Spoken Dialog Systems: A Review: Steve Young(Cambri">
<meta property="og:type" content="article">
<meta property="og:title" content="对话AI的论文列表">
<meta property="og:url" content="https://824zzy.github.io/2018/08/09/convAI-paper-list/index.html">
<meta property="og:site_name" content="Zhengyuan Zhu">
<meta property="og:description" content="论文列表格式&amp;emsp;论文发表年份： 论文题目&amp;论文链接：第一作者（第一作者所属学校&#x2F;机构），代码链接  OverviewExisting Models of Dialog SystemTask-Oriented Dialog 13: POMDP-Based Statistical Spoken Dialog Systems: A Review: Steve Young(Cambri">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2018-08-09T17:31:31.000Z">
<meta property="article:modified_time" content="2018-09-04T06:22:10.000Z">
<meta property="article:author" content="Zhengyuan Zhu">
<meta property="article:tag" content="chatbot">
<meta property="article:tag" content="conversationalAI">
<meta property="article:tag" content="nlp">
<meta property="article:tag" content="paper">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: 'undefined',
      author: 'Author'
    },
    algolia: {
      applicationID: '0BV7SDEYWS',
      apiKey: '7b5bee63a251ae508a2ab2b689f114c8',
      indexName: 'zzy824',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://824zzy.github.io/2018/08/09/convAI-paper-list/"/>





  <title>对话AI的论文列表 | Zhengyuan Zhu</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-111723881-1', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?605e0c55415d20ab6e7a9cd3fcb8f3e6";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




<meta name="generator" content="Hexo 5.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a target="_blank" rel="noopener" href="https://github.com/824zzy" class="github-corner" aria-label="View source on Github"><svg width="92" height="92" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Zhengyuan Zhu</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-book">
          <a href="/books" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            HandwritingNote
          </a>
        </li>
      
        
        <li class="menu-item menu-item-demo">
          <a href="/demo" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-play-circle"></i> <br />
            
            Playing
          </a>
        </li>
      
        
        <li class="menu-item menu-item-maze">
          <a href="/maze.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-code"></i> <br />
            
            Maze
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://824zzy.github.io/2018/08/09/convAI-paper-list/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhengyuan Zhu">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">对话AI的论文列表</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-09T12:31:31-05:00">
                2018-08-09
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2018-09-04T01:22:10-05:00">
                2018-09-04
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index">
                    <span itemprop="name">AI</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/08/09/convAI-paper-list/" class="leancloud_visitors" data-flag-title="对话AI的论文列表">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2,540
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  16分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <script src="/assets/js/APlayer.min.js"> </script><blockquote>
<p>论文列表格式<br>&emsp;论文发表年份： 论文题目&amp;论文链接：第一作者（第一作者所属学校/机构），代码链接</p>
</blockquote>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><h3 id="Existing-Models-of-Dialog-System"><a href="#Existing-Models-of-Dialog-System" class="headerlink" title="Existing Models of Dialog System"></a>Existing Models of Dialog System</h3><h4 id="Task-Oriented-Dialog"><a href="#Task-Oriented-Dialog" class="headerlink" title="Task-Oriented Dialog"></a>Task-Oriented Dialog</h4><ul>
<li>13: <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/6407655/"><strong>POMDP-Based Statistical Spoken Dialog Systems: A Review</strong></a>: Steve Young(Cambridge University)</li>
<li>11: <a target="_blank" rel="noopener" href="https://www.wiley.com/en-us/Spoken+Language+Understanding:+Systems+for+Extracting+Semantic+Information+from+Speech-p-9780470688243"><strong>Spoken Language Understanding: Systems for Extracting Semantic Information from Speech</strong></a>: Book!</li>
<li>11:<a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/D11-1054"><strong>Data-Driven Response Generation in Social Media</strong></a>: Alan Ritter(University of Washington Seattle)</li>
<li><p>15: <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf"><strong>A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</strong></a>: Alessandro Sordoni(Universite de Montreal)</p>
</li>
<li><p>15: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1506.05869.pdf"><strong>A Neural Conversational Model</strong></a>: Oriol Vinyals(Google), <a target="_blank" rel="noopener" href="https://github.com/Conchylicultor/DeepQA"><strong>code</strong></a> via tensorflow</p>
</li>
<li>15: <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P15-1152"><strong>Neural Responding Machine for Short-Text Conversation</strong></a>: Lifeng Shang(Noah’s Ark Lab), <a target="_blank" rel="noopener" href="https://github.com/stamdlee/DeepLearningFramework"><strong>code</strong></a> via theano and tensorflow</li>
</ul>
<h3 id="Traditional-NLP-component-stack"><a href="#Traditional-NLP-component-stack" class="headerlink" title="Traditional NLP component stack"></a>Traditional NLP component stack</h3><h4 id="Challenge-of-NLP"><a href="#Challenge-of-NLP" class="headerlink" title="Challenge of NLP"></a>Challenge of NLP</h4><ul>
<li>09: <a target="_blank" rel="noopener" href="https://www.cs.colorado.edu/~martin/slp.html"><strong>SPEECH and LANGUAGE PROCESSING An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Second Edition</strong></a>: book </li>
</ul>
<h3 id="Deep-Semantic-Similarity-Model-DSSM"><a href="#Deep-Semantic-Similarity-Model-DSSM" class="headerlink" title="Deep Semantic Similarity Model(DSSM)"></a>Deep Semantic Similarity Model(DSSM)</h3><h4 id="application-scenarios"><a href="#application-scenarios" class="headerlink" title="application scenarios"></a>application scenarios</h4><ol>
<li>Web search<ul>
<li>13: <a target="_blank" rel="noopener" href="http://dl.acm.org/citation.cfm?id=2505665"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), <a target="_blank" rel="noopener" href="https://github.com/wangtianqi1993/DL-WebSearch"><strong>code</strong></a> via tensorflow</li>
<li>14: <a target="_blank" rel="noopener" href="http://dl.acm.org/citation.cfm?doid=2661829.2661935"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.06922"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a target="_blank" rel="noopener" href="https://github.com/zhaosm/dssm-lstm"><strong>code</strong></a></li>
</ul>
</li>
<li>Entity linking<ul>
<li>14: <a target="_blank" rel="noopener" href="http://anthology.aclweb.org/D/D14/D14-1002.pdf"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfeng Gao(Microsoft Research)</li>
</ul>
</li>
<li>Image captioning<ul>
<li>15: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1411.4952"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li>
</ul>
</li>
<li>Machine Translation<ul>
<li><a target="_blank" rel="noopener" href="http://aclweb.org/anthology/P/P14/P14-1066.pdf"><strong>Learning Continuous Phrase Representations for Translation Modeling</strong></a>: Jianfeng Gao(Microsoft Research)</li>
</ul>
</li>
<li>Online recommendation<ul>
<li>[<strong>duplicate</strong>] 14: <a target="_blank" rel="noopener" href="http://anthology.aclweb.org/D/D14/D14-1002.pdf"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfneg Gao(Microsoft Research)</li>
</ul>
</li>
</ol>
<h4 id="Framework-of-Model"><a href="#Framework-of-Model" class="headerlink" title="Framework of Model"></a>Framework of Model</h4><ul>
<li>[<strong>duplicate</strong>] 13: <a target="_blank" rel="noopener" href="http://dl.acm.org/citation.cfm?id=2505665"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), [<strong>code</strong>]</li>
<li>[<strong>duplicate</strong>] 14: <a target="_blank" rel="noopener" href="http://dl.acm.org/citation.cfm?doid=2661829.2661935"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.06922"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a target="_blank" rel="noopener" href="https://github.com/zhaosm/dssm-lstm"><strong>code</strong></a></li>
<li><a target="_blank" rel="noopener" href="http://aka.ms/sent2vec">Sent2Vec</a>: software by microsoft</li>
</ul>
<h4 id="Go-beyound-DSSM"><a href="#Go-beyound-DSSM" class="headerlink" title="Go beyound DSSM"></a>Go beyound DSSM</h4><ul>
<li>[<strong>duplicate</strong>] 15: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1411.4952"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li>
</ul>
<hr>
<h2 id="Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC"><a href="#Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC" class="headerlink" title="Question answeriing(QA) and Machine Readiing Comprehension(MRC)"></a>Question answeriing(QA) and Machine Readiing Comprehension(MRC)</h2><h3 id="Open-Domain-Question-Answering"><a href="#Open-Domain-Question-Answering" class="headerlink" title="Open-Domain Question Answering"></a>Open-Domain Question Answering</h3><h4 id="Knowledge-Base-QA"><a href="#Knowledge-Base-QA" class="headerlink" title="Knowledge Base-QA"></a>Knowledge Base-QA</h4><ol>
<li>Symbolic approach via Large-scale knowledge graphs<ul>
<li>[<strong>oral</strong>] 98: <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf">MindNet: acquiring and structuring semantic information from text</a>: Stephen D.Richardson(Microsoft Research)</li>
<li>[<strong>oral</strong>] 13: <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/D13-1160">Semantic Parsing on Freebase from Question-Answer Pairs</a>: Jonathan Berant(Stanford University)</li>
<li>15: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1510.08565.pdf">Attention with Intention for a Neural Network Conversation Model</a>: Kaisheng Yao(Microsoft Research)</li>
<li>14: <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/P14-1091">Knowledge-Based Question Answering as Machine Translation</a>: Junwei Bao(Harbin Institute of Technology)</li>
<li>15: <a target="_blank" rel="noopener" href="http://aclweb.org/anthology/P15-1128">Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base</a>:Wen-tau Yih(Microsoft Research)</li>
</ul>
</li>
<li><p><strong>ReasoNet</strong> with Shared Memory</p>
<ul>
<li>[<strong>oral</strong>][<strong>duplicate</strong>] 16: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.04642.pdf?">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li>
<li>17: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1609.05284.pdf">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li>
</ul>
</li>
<li><p>Search Controller in <strong>ReasoNet</strong> </p>
<ul>
<li>[<strong>duplicate</strong>] 16: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.04642.pdf?">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li>
</ul>
</li>
<li><strong>ReasoNet</strong> in symbolic vs neural space<ul>
<li>Symbolic is comprehensible but not robust<ul>
<li>11: <a target="_blank" rel="noopener" href="http://www.cs.cmu.edu/~tom/pubs/lao-emnlp11.pdf">Random Walk Inference and Learning in A Large Scale Knowledge Base</a>:Ni Lao(Carnegie Mellon University)</li>
<li>98: <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf">MindNet: acquiring and structuring semantic information from text</a>:Stephen D.Richardson(Microsoft Research)</li>
</ul>
</li>
<li>Neural is robust but not comprehensible<ul>
<li>[<strong>duplicate</strong>] 16: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.04642.pdf?">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li>
<li>[<strong>oral</strong>] 15: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1412.6575">EMBEDDING ENTITIES AND RELATIONS FOR LEARNING AND INFERENCE IN KNOWLEDGE BASES</a>:Bishan Yang(Cornell University), <a target="_blank" rel="noopener" href="https://github.com/thunlp/OpenKE/blob/master/models/DistMult.py">TensorFlow code</a>, <a target="_blank" rel="noopener" href="https://github.com/thunlp/OpenKE/blob/OpenKE-PyTorch/models/DistMult.py">PyTorch code</a></li>
</ul>
</li>
<li>Hybrid is robust and  comprehensible<ul>
<li>18: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.04394.pdf">M-Walk: Learning to Walk in Graph with Monte Carlo Tree Search</a>:Yelong Shen(Microsoft Research&amp;Tecent AI Lab)</li>
<li>18: [<strong>oral</strong>] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.06690">DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning</a>:Wenhan Xiong(University of California,Santa Barbara), <a target="_blank" rel="noopener" href="https://github.com/xwhan/DeepPath">code1</a> <a target="_blank" rel="noopener" href="https://github.com/arunarn2/DeepPathwithTensorforce">code2</a></li>
<li>18: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.05851">GO FOR A WALK AND ARRIVE AT THE ANSWER: REASONING OVER PATHS IN KNOWLEDGE BASES USING REINFORCEMENT LEARNING</a>:Rajarshi Das(University of Massachusetts,Amherst), </li>
</ul>
</li>
</ul>
</li>
<li>Multi-turn KB-QA<ul>
<li><del>Programmed Dialogue policy</del><ul>
<li><del>15: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1504.07182.pdf">A Probabilistic Framework for Representing Dialog Systems and Entropy-Based Dialog Management through Dynamic Stochastic State Evolution</a>:Ji Wu(IEEE)</del></li>
</ul>
</li>
<li>Trained via RL Dialogue policy<ul>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.01337">Neural Generative Question Answering </a>:Jun Yin(Noah’s Ark Lab, Huawe) <a target="_blank" rel="noopener" href="https://github.com/jxfeb/Generative_QA">corpus</a></li>
<li>[<strong>oral</strong>] 16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1604.04562">A Network-based End-to-End Trainable Task-oriented Dialogue System</a>:Tsung-Hsien Wen(Cambridge University), <a target="_blank" rel="noopener" href="https://github.com/shawnwun/NNDIAL">Theano code</a></li>
<li>[<strong>oral</strong>] 17: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1609.00777">Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a>:Bhuwan Dhingra(Carnegie Mellon University), <a target="_blank" rel="noopener" href="https://github.com/MiuLab/KB-InfoBot">Theano code</a></li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="Text-QA"><a href="#Text-QA" class="headerlink" title="Text-QA"></a>Text-QA</h4><ol>
<li>MS MARCO<ul>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.09268">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</a>:Tri Nguyan(Microsoft AI&amp;Research)</li>
</ul>
</li>
<li>SQuAD<ul>
<li>16: <a target="_blank" rel="noopener" href="https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a>:Pranav Rajpurkar(Stanford University)</li>
</ul>
</li>
</ol>
<h3 id="Neural-MRC-Models"><a href="#Neural-MRC-Models" class="headerlink" title="Neural MRC Models"></a>Neural MRC Models</h3><h4 id="BiDAF"><a href="#BiDAF" class="headerlink" title="BiDAF"></a>BiDAF</h4><ul>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.01603.pdf">BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION</a>:Minjoon Seo(University of Washington)<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/imraviagrawal/ReadingComprehension">code1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/bentrevett/bidaf">code2</a> </li>
<li><a target="_blank" rel="noopener" href="https://github.com/akhil-vader/MachineComprehension_SQuAD">code3</a> </li>
<li><a target="_blank" rel="noopener" href="https://github.com/RamkishanPanthena/Machine-Comprehension-using-SQuAD-Dataset">code4</a></li>
</ul>
</li>
</ul>
<h4 id="SAN"><a href="#SAN" class="headerlink" title="SAN"></a>SAN</h4><ul>
<li>18: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1712.03556.pdf">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a target="_blank" rel="noopener" href="https://github.com/kevinduh/san_mrc">code</a></li>
</ul>
<h4 id="Neural-MRC-Models-on-SQuAD"><a href="#Neural-MRC-Models-on-SQuAD" class="headerlink" title="Neural MRC Models on SQuAD"></a><strong>Neural MRC Models on SQuAD</strong></h4><ol>
<li><p>Encoding: map each text span to a semantic vector</p>
<ul>
<li>Word Embedding<ul>
<li>14: <a target="_blank" rel="noopener" href="https://nlp.stanford.edu/pubs/glove.pdf">GloVe: Global Vectors for Word Representation</a>:Jeffrey Pennington(Stanford University)<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/brangerbriz/midi-glove">code:midi-glove</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/fdurant/wiki_glove">code:wiki-glove</a></li>
</ul>
</li>
<li>13: <a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed Representations of Words and Phrases and their Compositionality</a>:Tomas Mikolov(Google Inc.)<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/brijml/mikolov_word2vec">code1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/shuuchen/keras_word2vec">code2</a></li>
</ul>
</li>
</ul>
</li>
<li><p>Context Embedding</p>
<ol>
<li><p>capture context info for each word</p>
<ul>
<li>16: <a target="_blank" rel="noopener" href="http://aclweb.org/anthology/K16-1006">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li>
<li>18: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.05365">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a target="_blank" rel="noopener" href="https://github.com/zqhZY/ner_elmo">code</a></li>
<li>18: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1804.09541.pdf">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ni9elf/QANet">code1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/BangLiu/QANet-PyTorch">code2</a></li>
</ul>
</li>
</ul>
</li>
<li><p>Context Embedding via BiLSTM/ELmo</p>
<ul>
<li>[<strong>duplicate</strong>] 18: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.05365">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a target="_blank" rel="noopener" href="https://github.com/zqhZY/ner_elmo">code</a></li>
<li>17: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.00107">Learned in Translation: Contextualized Word Vectors</a>:Bryan McCann(SalesForce)</li>
<li>16: [duplicate]<a target="_blank" rel="noopener" href="http://aclweb.org/anthology/K16-1006">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li>
</ul>
</li>
<li><p>Context Embedding</p>
<ul>
<li>[<strong>duplicate</strong>] 18: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1804.09541.pdf">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ni9elf/QANet">code1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/BangLiu/QANet-PyTorch">code2</a></li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<ul>
<li>Query-context/Content-query attention</li>
</ul>
</li>
<li><p>Reasoning: rank and re-rank semantic vectors</p>
<ul>
<li><p>Multi-step reasoning for Text-QA</p>
<ul>
<li>[<strong>duplicate</strong>] 17: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1609.05284.pdf">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li>
</ul>
</li>
<li><p>Stochastic Answer Net</p>
<ul>
<li>[<strong>duplicate</strong>] 18: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1712.03556.pdf">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a target="_blank" rel="noopener" href="https://github.com/kevinduh/san_mrc">code</a></li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="Task-oriented-dialogues"><a href="#Task-oriented-dialogues" class="headerlink" title="Task-oriented dialogues"></a>Task-oriented dialogues</h2><h3 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h3><h4 id="A-Example-Dialogue-with-Movie-Bot"><a href="#A-Example-Dialogue-with-Movie-Bot" class="headerlink" title="A Example Dialogue with Movie-Bot"></a>A Example Dialogue with Movie-Bot</h4><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/MiuLab/TC-Bot">source code</a></li>
</ul>
<h4 id="Conversation-as-Reinforcement-Learning"><a href="#Conversation-as-Reinforcement-Learning" class="headerlink" title="Conversation as Reinforcement Learning"></a>Conversation as Reinforcement Learning</h4><ul>
<li>00: <a target="_blank" rel="noopener" href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf">A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies</a>: Esther Levin(IEEE)</li>
<li>00: <a target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf">Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System</a>:Satinder Singh(AT&amp;T Labs)</li>
<li>07: <a target="_blank" rel="noopener" href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li>
</ul>
<h4 id="Dialogue-System-Evaluation-Simulated-Users"><a href="#Dialogue-System-Evaluation-Simulated-Users" class="headerlink" title="Dialogue System Evaluation(Simulated Users)"></a>Dialogue System Evaluation(Simulated Users)</h4><ol>
<li>Agenda based<ul>
<li>09: <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/4806280/">The Hidden Agenda User Simulation Model</a>:Jost Schatzmann(IEEE)</li>
<li><a target="_blank" rel="noopener" href="https://github.com/MiuLab/TC-Bot">source code</a> </li>
</ul>
</li>
<li>Model based<ul>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1607.00070">A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems</a>: Layla El Asri(Maluuba Research)</li>
<li>17: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.01008.pdf">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li>
</ul>
</li>
</ol>
<h3 id="traditional-approache"><a href="#traditional-approache" class="headerlink" title="traditional approache"></a>traditional approache</h3><h4 id="Decison-theoretic-View-of-Dialogue-Management"><a href="#Decison-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decison-theoretic View of Dialogue Management"></a>Decison-theoretic View of Dialogue Management</h4><ul>
<li>[<strong>duplicate</strong>] 00: <a target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf">Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System</a>:Satinder Singh(AT&amp;T Labs)</li>
<li>00: <a target="_blank" rel="noopener" href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf">A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies</a>: Esther Levin(IEEE)</li>
<li>00: <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/P98-2219">Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email</a>: Marilyn A.Walker(ATT Labs Research)</li>
<li>02: <a target="_blank" rel="noopener" href="https://dl.acm.org/citation.cfm?id=1289246">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</a>:Konrad Scheffler(Cambridge University)</li>
</ul>
<h4 id="Language-Understanding-Uncertainty-POMDP-as-a-principled-framework"><a href="#Language-Understanding-Uncertainty-POMDP-as-a-principled-framework" class="headerlink" title="Language Understanding Uncertainty: POMDP as a principled framework"></a>Language Understanding Uncertainty: POMDP as a principled framework</h4><ul>
<li>00: <a target="_blank" rel="noopener" href="http://www.mit.edu/~nickroy/papers/acl00.pdf">Spoken Dialogue Management Using Probabilistic Reasoning</a>: Nicholas Roy(Carnegie Mellon University)</li>
<li>01: <a target="_blank" rel="noopener" href="http://www.wytsg.org:88/reslib/400/180/110/020/010/130/L000000000233767.pdf">Spoken Dialogue Management as Planning and Acting under Uncertainty</a>:Bo Zhang(Tech. of China)</li>
<li>07: <a target="_blank" rel="noopener" href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li>
</ul>
<h4 id="scaling-up-Dialogue-Optimization"><a href="#scaling-up-Dialogue-Optimization" class="headerlink" title="scaling up Dialogue Optimization"></a>scaling up Dialogue Optimization</h4><ol>
<li>Use approxmiate POMDP algorithms leveraging problem-specific structure<ul>
<li>00: <a target="_blank" rel="noopener" href="http://www.mit.edu/~nickroy/papers/acl00.pdf">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</a>:Konrad Scheffler(Cambridge University)</li>
<li>07: <a target="_blank" rel="noopener" href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li>
</ul>
</li>
<li>Use Reinforcement Learning algorithms with function approximation<ul>
<li>08: <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/J08-4002">Hybrid Reinforcement/Supervised Learning of Dialogue Policies from Fixed Data Sets</a>: James Henderson</li>
<li>09: <a target="_blank" rel="noopener" href="https://pdfs.semanticscholar.org/a950/d7836e101e7d649791714d8383a804a6f671.pdf">Reinforcement Learning for Dialog Management using Least-Squares Policy Iteration and Fast Feature Selection</a>: Lihong Li(Rutgers University)</li>
<li>14: <a target="_blank" rel="noopener" href="http://mi.eng.cam.ac.uk/~sjy/papers/gktb14.pdf">Incremental on-line adaptation of POMDP-based dialogue managers to extended domains</a>:M.Gasic[Cambridge University]</li>
</ul>
</li>
</ol>
<h3 id="Natural-language-understanding-and-dialogue-state-tracking"><a href="#Natural-language-understanding-and-dialogue-state-tracking" class="headerlink" title="Natural language understanding and dialogue state tracking"></a>Natural language understanding and dialogue state tracking</h3><h4 id="Language-Understanding"><a href="#Language-Understanding" class="headerlink" title="Language Understanding"></a>Language Understanding</h4><ol>
<li><p>DNN for Domain/Intent Classification</p>
<ul>
<li>15:  <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/RNNLM_addressee.pdf">Recurrent Neural Network and LSTM Models for Lexical Utterance Classification</a>: Suman Raviuri(University of California,Berkeley)</li>
</ul>
</li>
<li><p>Slot filling</p>
<ul>
<li>16: <a target="_blank" rel="noopener" href="https://www.csie.ntu.edu.tw/~yvchen/doc/IS16_MultiJoint.pdf">Multi-Domain Joint Semantic Frame Parsing using Bi-directional RNN-LSTM</a>: Dilek Hakkani-Tur(Microsoft Research)</li>
</ul>
</li>
<li><p>Further details on NLU</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.csie.ntu.edu.tw/~yvchen/doc/OpenDialogue_Tutorial_IJCNLP.pdf">ppt</a></li>
<li>E2E MemNN for Contectual LU: <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/IS16_ContextualSLU.pdf">End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding</a>: Yun-Nung Chen(National Taiwan University )</li>
<li>[<strong>duplicate</strong>] LU Importance: 17: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.01008.pdf">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li>
</ul>
</li>
</ol>
<h4 id="Dialogue-State-Tracking-DST"><a href="#Dialogue-State-Tracking-DST" class="headerlink" title="Dialogue State Tracking(DST)"></a>Dialogue State Tracking(DST)</h4><ol>
<li>DSTC(Dialog State Tracking Challenge)<ul>
<li><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/">DSTC1 official website</a></li>
<li><a target="_blank" rel="noopener" href="http://camdial.org/~mh521/dstc/">DSTC2&amp;3 official website</a></li>
<li><a target="_blank" rel="noopener" href="http://www.colips.org/workshop/dstc4/">DSTC4 official website</a></li>
<li><a target="_blank" rel="noopener" href="http://workshop.colips.org/dstc5/">DSTC5 official website</a></li>
</ul>
</li>
<li><p>Neural Belief Tracker</p>
<ul>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.03777">Neural Belief Tracker: Data-Driven Dialogue State Tracking</a>: Nikola Mrksic(University of Cambridge)</li>
</ul>
</li>
<li><p>NN-Based DST</p>
<ul>
<li>13: <a target="_blank" rel="noopener" href="http://www.anthology.aclweb.org/W/W13/W13-4073.pdf">Deep Neural Network Approach for the Dialog State Tracking Challenge</a>: Matthew Henderson(University of Cambridge)</li>
<li>15: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.07190">Multi-domain Dialog State Tracking using Recurrent Neural Networks</a>: Nikola Mrksic(University of Cambridge)</li>
<li>[<strong>duplicate</strong>] 16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.03777">Neural Belief Tracker: Data-Driven Dialogue State Tracking</a>: Nikola Mrksic(University of Cambridge)</li>
</ul>
</li>
</ol>
<h3 id="Deep-RL-for-dialogue-policy-learning"><a href="#Deep-RL-for-dialogue-policy-learning" class="headerlink" title="Deep RL for dialogue policy learning"></a>Deep RL for dialogue policy learning</h3><h4 id="Two-main-classed-of-RL-algorithms"><a href="#Two-main-classed-of-RL-algorithms" class="headerlink" title="Two main classed of RL algorithms"></a>Two main classed of RL algorithms</h4><ol>
<li>Value function based:<ul>
<li>15: <a target="_blank" rel="noopener" href="https://www.nature.com/articles/nature14236">Human-level control through deep reinforcement learning</a>: Volodymyr Minh<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/devsisters/DQN-tensorflow">code1</a> by tensorflow</li>
<li><a target="_blank" rel="noopener" href="https://github.com/pianomania/DQN-pytorch">code2</a> by pytorch</li>
</ul>
</li>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1606.02560.pdf">Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning</a>: Tiancheng Zhao(Carnegie Mellon University)</li>
</ul>
</li>
<li>Policy based:<ul>
<li>92: <a target="_blank" rel="noopener" href="https://doi.org/10.1007/BF00992696">Simple statistical gradient-following algorithms for connectionist reinforcement learning</a>: Ronald J.Williams</li>
<li>17: <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/P/P16/P16-1230.pdf">On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems</a>: Pei-Hao Su(University of Cambridge)</li>
</ul>
</li>
</ol>
<h4 id="Domain-Extension-and-Exploration-BBQ-network"><a href="#Domain-Extension-and-Exploration-BBQ-network" class="headerlink" title="Domain Extension and Exploration(BBQ network)"></a>Domain Extension and Exploration(BBQ network)</h4><ul>
<li>18: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1608.05081.pdf">BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems</a>: Zachary Lipton(Carnegir Mellon University)</li>
</ul>
<h4 id="Composite-task-Dialogues"><a href="#Composite-task-Dialogues" class="headerlink" title="Composite-task Dialogues"></a>Composite-task Dialogues</h4><ol>
<li>A Hierarchical Policy Learner<ul>
<li>98: <a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/1384-reinforcement-learning-with-hierarchies-of-machines.pdf">Reinforcement Learning with Hierarchies of Machines</a>: Ronald Parr(UC Berkeley)</li>
<li>17: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1704.03084">Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning</a>: Baolin Peng(Microsoft Research)</li>
</ul>
</li>
<li>Integrating Planning for Dialogue Policy Learning<ul>
<li>18: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1801.06176">Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy Learning</a>: Baolin Peng(Microsoft Research) , <a target="_blank" rel="noopener" href="https://github.com/MiuLab/DDQ">code</a></li>
</ul>
</li>
</ol>
<h3 id="Decision-theoretic-View-of-Dialogue-Management"><a href="#Decision-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decision-theoretic View of Dialogue Management"></a>Decision-theoretic View of Dialogue Management</h3><h4 id="Hybrid-Code-Networks"><a href="#Hybrid-Code-Networks" class="headerlink" title="Hybrid Code Networks"></a>Hybrid Code Networks</h4><ul>
<li>17: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1702.03274">Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning</a>: Jason D. Williams(Microsoft Research)</li>
</ul>
<h4 id="Differentiating-KB-Accesses"><a href="#Differentiating-KB-Accesses" class="headerlink" title="Differentiating KB Accesses"></a>Differentiating KB Accesses</h4><ul>
<li>[<strong>duplicate</strong>] 17: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1609.00777">Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a>:Bhuwan Dhingra(Carnegie Mellon University)</li>
</ul>
<h4 id="An-E2E-Neural-Dialogue-System"><a href="#An-E2E-Neural-Dialogue-System" class="headerlink" title="An E2E Neural Dialogue System"></a>An E2E Neural Dialogue System</h4><ul>
<li>[<strong>duplicate</strong>] 17: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.01008.pdf">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li>
</ul>
<hr>
<h2 id="Fully-data-driven-conversation-models-and-chatbots"><a href="#Fully-data-driven-conversation-models-and-chatbots" class="headerlink" title="Fully data-driven conversation models and chatbots"></a>Fully data-driven conversation models and chatbots</h2><h3 id="Historical-overview"><a href="#Historical-overview" class="headerlink" title="Historical overview"></a>Historical overview</h3><h4 id="Response-retrival-system"><a href="#Response-retrival-system" class="headerlink" title="Response retrival system"></a>Response retrival system</h4><ul>
<li>10: <a target="_blank" rel="noopener" href="https://aritter.github.io/chat.pdf">Filter, Rank, and Transfer the Knowledge: Learning to Chat</a>:<br>Alan Ritter(University of Washington)</li>
</ul>
<h4 id="Response-generation-using-Statistical-Machine-Translation"><a href="#Response-generation-using-Statistical-Machine-Translation" class="headerlink" title="Response generation using Statistical Machine Translation"></a>Response generation using Statistical Machine Translation</h4><ul>
<li>11:  <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/D11-1054">Data-Driven Response Generation in Social Media</a>: Alan Ritter(University of Washington)</li>
</ul>
<h4 id="First-neural-response-generation-systems"><a href="#First-neural-response-generation-systems" class="headerlink" title="First neural response generation systems"></a>First neural response generation systems</h4><ol>
<li>Neural Models for Response Generation<ul>
<li>15: <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a>: Alessandro Sordoni(University de Montreal)</li>
<li>15: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1506.05869.pdf">A Neural Conversational Model</a>: Oriol Vinyals(Google .Inc)</li>
<li>15: <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P15-1152">Neural Responding Machine for Short-Text Conversation</a>: Lifeng Shang(Noah’s Ark Lab), <a target="_blank" rel="noopener" href="https://github.com/stamdlee/DeepLearningFramework">code</a></li>
</ul>
</li>
<li>Neural conversation engine: <ul>
<li>16: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1510.03055">A Diversity-Promoting Objective Function for Neural Conversation Models</a>: Jiwei Li(Stanford University)</li>
</ul>
</li>
</ol>
<h3 id="challenges-and-remedies"><a href="#challenges-and-remedies" class="headerlink" title="challenges and remedies"></a>challenges and remedies</h3><h4 id="Challenge-The-blandness-problem"><a href="#Challenge-The-blandness-problem" class="headerlink" title="Challenge: The blandness problem"></a>Challenge: The blandness problem</h4><ul>
<li>[<strong>duplicate</strong>] 16: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1510.03055">A Diversity-Promoting Objective Function for Neural Conversation Models</a>: Jiwei Li(Stanford University)</li>
</ul>
<h4 id="Challenge-The-consistency-problem"><a href="#Challenge-The-consistency-problem" class="headerlink" title="Challenge: The consistency problem"></a>Challenge: The consistency problem</h4><ol>
<li>Solution: Personalized Response Generation<ul>
<li>Microsoft Personality chat:speaker embedding LSTM: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1603.06155">A Persona-Based Neural Conversation Model</a>: Jiwei Li(Stanford University), <a target="_blank" rel="noopener" href="https://github.com/fionn-mac/A-Persona-Based-Neural-Conversation-Model">code</a> via Pytorch</li>
</ul>
</li>
<li>Personal modeling as multi-task learning<ul>
<li>17: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.07388">Multi-Task Learning for Speaker-Role Adaptation in Neural Conversation Models</a>: Yi Luan(University of Washington)</li>
</ul>
</li>
<li>Improving personalization with multiple losses<ul>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1606.00372.pdf">Conversational Contextual Cues: The Case of Personalization and History for Response Ranking</a>: Rami Al-Rfou(Google .Inc)</li>
</ul>
</li>
</ol>
<h4 id="Challenge-Long-conversational-context"><a href="#Challenge-Long-conversational-context" class="headerlink" title="Challenge: Long conversational context"></a>Challenge: Long conversational context</h4><ol>
<li>It can be challenging for LSTM/GRU to encode very long context<ul>
<li>18: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.04623">Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context</a>: Urvashi Khadelwal(Stanford University)</li>
</ul>
</li>
<li>Hierarchical Encoder-Decoder(HRED), <a target="_blank" rel="noopener" href="https://github.com/urvashik/lm-context-analysis">code</a><ul>
<li>16: <a target="_blank" rel="noopener" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160">Building End-to-End Dialogue Systems Using Generative Hierarchical Neural Network Models</a>: Iulian V.Serban(University de Montreal), <a target="_blank" rel="noopener" href="https://github.com/hsgodhia/hred">code</a></li>
</ul>
</li>
<li>Hierarchical Latent Variable Encoder-Decoder(VHRED)<ul>
<li>17: <a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~lcharlin/papers/vhred_aaai17.pdf">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a>: Iulian V. Serban</li>
</ul>
</li>
</ol>
<h3 id="Grounded-conversation-models"><a href="#Grounded-conversation-models" class="headerlink" title="Grounded conversation models"></a>Grounded conversation models</h3><h4 id="A-Knowledge-Grounded-Neural-Conversation-Model"><a href="#A-Knowledge-Grounded-Neural-Conversation-Model" class="headerlink" title="A Knowledge-Grounded Neural Conversation Model"></a>A Knowledge-Grounded Neural Conversation Model</h4><ul>
<li>15: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1503.08895.pdf">End-To-End Memory Networks</a>: Sainbayar Sukhbaatar(New York University)<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/carpedm20/MemN2N-tensorflow">code1</a> via Tensorflow</li>
<li><a target="_blank" rel="noopener" href="https://github.com/domluna/memn2n">code2</a> via Tensorflow</li>
<li><a target="_blank" rel="noopener" href="https://github.com/vinhkhuc/MemN2N-babi-python">code3</a> for bAbI QA tasks</li>
</ul>
</li>
<li>17: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1702.01932">A Knowledge-Grounded Neural Conversation Model</a>: Marjan Gahzvininejad(USC)</li>
</ul>
<h4 id="Grounded-E2E-Dialogue-Systems"><a href="#Grounded-E2E-Dialogue-Systems" class="headerlink" title="Grounded E2E Dialogue Systems"></a>Grounded E2E Dialogue Systems</h4><ul>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.08669">Visual Dialog</a>: Abhishek Das(Georgia Institute of Tehhnology)<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/batra-mlp-lab/visdial">code1</a> via Lua</li>
<li><a target="_blank" rel="noopener" href="https://github.com/jiasenlu/visDial.pytorch">code2</a> via Pytorch</li>
</ul>
</li>
<li>17: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1701.08251">Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation</a>: Nasrin Mostafazadeh(University of Rochster)</li>
<li>18: <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/uploads/prod/2018/04/huber2018chi.small_.pdf">Emotional Dialogue Generation using Image-Grounded Language Models</a>:Bernd Huber(Harvard University)</li>
</ul>
<h3 id="Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue"><a href="#Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue" class="headerlink" title="Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)"></a>Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)</h3><ul>
<li>16: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.01541">Deep Reinforcement Learning for Dialogue Generation</a>:Jiwei Li(Stanford University)<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/liuyuemaicha/Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow">code1</a> via Tensorflow</li>
<li><a target="_blank" rel="noopener" href="https://github.com/agsarthak/Goal-oriented-Dialogue-Systems">code2</a> via keras</li>
<li><a target="_blank" rel="noopener" href="https://github.com/jiweil/Neural-Dialogue-Generation">code3</a> by Jiwei Li</li>
</ul>
</li>
</ul>
<h3 id="Data-and-evaluation"><a href="#Data-and-evaluation" class="headerlink" title="Data and evaluation"></a>Data and evaluation</h3><h4 id="Conversational-datasets-for-social-bots-E2E-dialogue-research"><a href="#Conversational-datasets-for-social-bots-E2E-dialogue-research" class="headerlink" title="Conversational datasets(for social bots, E2E dialogue research)"></a>Conversational datasets(for social bots, E2E dialogue research)</h4><ul>
<li>15: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.05742">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a>: Iulian Vlad Serban(Universite de Montreal)</li>
</ul>
<h4 id="Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation"><a href="#Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation" class="headerlink" title="Evaluating E2E Dialogue Systems via Autumatic evaluation"></a>Evaluating E2E Dialogue Systems via Autumatic evaluation</h4><ol>
<li>Machine-Translation-Based Metric<ul>
<li>02: <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P02-1040.pdf">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a target="_blank" rel="noopener" href="https://github.com/abidasari/NLPHW4">code</a></li>
<li>02: <a target="_blank" rel="noopener" href="http://www.mt-archive.info/HLT-2002-Doddington.pdf">Automatic Evaluation of Machine Translation Quality Using N-gram Co-Occurrence Statistics</a>: George Doddington</li>
</ul>
</li>
<li>Sentence-level correlation of MT metrics:<ul>
<li>16: <a target="_blank" rel="noopener" href="https://aclweb.org/anthology/D16-1230">How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation</a>: Chia-Wei Liu(McGill University)</li>
<li>15: <a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/N15-1124">Accurate Evaluation of Segment-level Machine Translation Metrics</a>: Yvette Graham(The University of Melbourne)</li>
</ul>
</li>
</ol>
<h4 id="The-importance-of-sample-size"><a href="#The-importance-of-sample-size" class="headerlink" title="The importance of sample size"></a>The importance of sample size</h4><ul>
<li>[<strong>duplicate</strong>] 02: <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P02-1040.pdf">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a target="_blank" rel="noopener" href="https://github.com/abidasari/NLPHW4">code</a></li>
<li>06: <a target="_blank" rel="noopener" href="http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf">Statistical Significance Tests for Machine Translation Evaluation</a>: Philipp Kowehn(MIT)</li>
</ul>
<h4 id="Corpus-level-Correlation"><a href="#Corpus-level-Correlation" class="headerlink" title="Corpus-level Correlation"></a>Corpus-level Correlation</h4><ul>
<li>[<strong>duplicate</strong>] 02: <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P02-1040.pdf">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a target="_blank" rel="noopener" href="https://github.com/abidasari/NLPHW4">code</a></li>
<li>[<strong>duplicate</strong>] 06: <a target="_blank" rel="noopener" href="http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf">Statistical Significance Tests for Machine Translation Evaluation</a>: </li>
</ul>
<h3 id="Chatbot-in-public"><a href="#Chatbot-in-public" class="headerlink" title="Chatbot in public"></a>Chatbot in public</h3><h4 id="Social-Bots-commercial-systems"><a href="#Social-Bots-commercial-systems" class="headerlink" title="Social Bots: commercial systems"></a>Social Bots: commercial systems</h4><ol>
<li>For end users<ul>
<li>Replika.ai system description: <a target="_blank" rel="noopener" href="https://github.com/lukalabs/replika-research/blob/master/scai2017/replika_ai.pdf">replika_ai</a>: Slides</li>
<li>XiaoIce:<br>15:<a target="_blank" rel="noopener" href="https://www.nytimes.com/interactive/2015/07/27/science/chatting-with-xiaoice.html">Chatting With Xiaoice</a>: News</li>
</ul>
</li>
<li>For bot developers<ul>
<li>[<strong>duplicate</strong>] Microsoft Personality chat:speaker embedding LSTM: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1603.06155">A Persona-Based Neural Conversation Model</a>: Jiwei Li(Stanford University), <a target="_blank" rel="noopener" href="https://github.com/fionn-mac/A-Persona-Based-Neural-Conversation-Model">code</a> via Pytorch</li>
<li>Microsoft Personality chat’s API: <a target="_blank" rel="noopener" href="https://labs.cognitive.microsoft.com/en-us/project-personality-chat">Project Personality Chat’s url</a> </li>
</ul>
</li>
</ol>
<h4 id="Open-Benchmarks"><a href="#Open-Benchmarks" class="headerlink" title="Open Benchmarks"></a>Open Benchmarks</h4><ol>
<li><p>Alexa Challenge</p>
<ul>
<li>website: <a target="_blank" rel="noopener" href="https://developer.amazon.com/alexaprize/proceedings">Alexa Prize Proceedings</a></li>
</ul>
</li>
<li><p>Dialogue System Technology Challenge(DSTC)</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://workshop.colips.org/dstc7">DSTC7</a></li>
<li>Visual-Scene: <a target="_blank" rel="noopener" href="https://github.com/hudaAlamri/DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge">DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge 2018</a></li>
<li>background article:<br><a target="_blank" rel="noopener" href="https://github.com/DSTC-MSR-NLP/DSTC7-End-to-End-Conversation-Modeling">DSTC7-End-to-End-Conversation-Modeling 2018</a></li>
<li>Registration Link:<br><a target="_blank" rel="noopener" href="http://workshop.colips.org/dstc7/call.html">DSTC7 Registration</a></li>
</ul>
</li>
</ol>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>请zzy824喝杯咖啡</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1ftpprdhc4gj20tz14q4a1.jpg" alt=" WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1ftppqm04y6j20go0p0jy4.jpg" alt=" Alipay"/>
        <p>Alipay</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:</strong>
    Zhengyuan Zhu
  </li>
  <li class="post-copyright-link">
    <strong>Post link:</strong>
    <a href="https://824zzy.github.io/2018/08/09/convAI-paper-list/" title="对话AI的论文列表">https://824zzy.github.io/2018/08/09/convAI-paper-list/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice: </strong>
    All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/chatbot/" rel="tag"><i class="fa fa-tag"></i> chatbot</a>
          
            <a href="/tags/conversationalAI/" rel="tag"><i class="fa fa-tag"></i> conversationalAI</a>
          
            <a href="/tags/nlp/" rel="tag"><i class="fa fa-tag"></i> nlp</a>
          
            <a href="/tags/paper/" rel="tag"><i class="fa fa-tag"></i> paper</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div id="needsharebutton-postbottom">
            <span class="btn">
              <i class="fa fa-share-alt" aria-hidden="true"></i>
            </span>
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/08/08/convAI-map-and-term/" rel="next" title="对话AI的术语和学习地图">
                <i class="fa fa-chevron-left"></i> 对话AI的术语和学习地图
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/08/18/paper-note-deep-reinfocement-learning-for-Dialogue-Generation/" rel="prev" title="论文笔记：Deep Reinforcement Learning for Dialogue Generation">
                论文笔记：Deep Reinforcement Learning for Dialogue Generation <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zODQxMS8xNDkzOQ"></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

			<!--my custom code begin-->
			<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
			<script src="https://cdnjs.cloudflare.com/ajax/libs/velocity/1.5.0/velocity.min.js"></script>
			<script type="text/javascript">
			  $("#sidebar").hover(function(){
				$("#mydivshow").velocity('stop').velocity({opacity: 1});
			  },function(){
				$("#mydivshow").velocity('stop').velocity({opacity: 0});
			  });
			</script>
			<div id="mydivshow" class="mydivshow">
			<!--my custom code end-->
			
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives%7C%7C%20archive">
              
                  <span class="site-state-item-count">72</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">28</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">90</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/824zzy" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:zhuzhengyuan824@gmail.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.zhihu.com/people/zzy-78/activities" target="_blank" title="知乎">
                    
                      <i class="fa fa-fw fa-bell"></i>知乎</a>
                </span>
              
            
          </div>

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://github.com/BUPT/awesome-chatbot" title="Chatbot主页" target="_blank">Chatbot主页</a>
                  </li>
                
              </ul>
            </div>
          

          
        </div>
		<!--my custom code begin-->
		</div>
		<!--my custom code end-->
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Overview"><span class="nav-number">1.</span> <span class="nav-text">Overview</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Existing-Models-of-Dialog-System"><span class="nav-number">1.1.</span> <span class="nav-text">Existing Models of Dialog System</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Task-Oriented-Dialog"><span class="nav-number">1.1.1.</span> <span class="nav-text">Task-Oriented Dialog</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Traditional-NLP-component-stack"><span class="nav-number">1.2.</span> <span class="nav-text">Traditional NLP component stack</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Challenge-of-NLP"><span class="nav-number">1.2.1.</span> <span class="nav-text">Challenge of NLP</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-Semantic-Similarity-Model-DSSM"><span class="nav-number">1.3.</span> <span class="nav-text">Deep Semantic Similarity Model(DSSM)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#application-scenarios"><span class="nav-number">1.3.1.</span> <span class="nav-text">application scenarios</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Framework-of-Model"><span class="nav-number">1.3.2.</span> <span class="nav-text">Framework of Model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Go-beyound-DSSM"><span class="nav-number">1.3.3.</span> <span class="nav-text">Go beyound DSSM</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC"><span class="nav-number">2.</span> <span class="nav-text">Question answeriing(QA) and Machine Readiing Comprehension(MRC)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Open-Domain-Question-Answering"><span class="nav-number">2.1.</span> <span class="nav-text">Open-Domain Question Answering</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Knowledge-Base-QA"><span class="nav-number">2.1.1.</span> <span class="nav-text">Knowledge Base-QA</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Text-QA"><span class="nav-number">2.1.2.</span> <span class="nav-text">Text-QA</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-MRC-Models"><span class="nav-number">2.2.</span> <span class="nav-text">Neural MRC Models</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#BiDAF"><span class="nav-number">2.2.1.</span> <span class="nav-text">BiDAF</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SAN"><span class="nav-number">2.2.2.</span> <span class="nav-text">SAN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Neural-MRC-Models-on-SQuAD"><span class="nav-number">2.2.3.</span> <span class="nav-text">Neural MRC Models on SQuAD</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Task-oriented-dialogues"><span class="nav-number">3.</span> <span class="nav-text">Task-oriented dialogues</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#overview"><span class="nav-number">3.1.</span> <span class="nav-text">overview</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#A-Example-Dialogue-with-Movie-Bot"><span class="nav-number">3.1.1.</span> <span class="nav-text">A Example Dialogue with Movie-Bot</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Conversation-as-Reinforcement-Learning"><span class="nav-number">3.1.2.</span> <span class="nav-text">Conversation as Reinforcement Learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dialogue-System-Evaluation-Simulated-Users"><span class="nav-number">3.1.3.</span> <span class="nav-text">Dialogue System Evaluation(Simulated Users)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#traditional-approache"><span class="nav-number">3.2.</span> <span class="nav-text">traditional approache</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Decison-theoretic-View-of-Dialogue-Management"><span class="nav-number">3.2.1.</span> <span class="nav-text">Decison-theoretic View of Dialogue Management</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Language-Understanding-Uncertainty-POMDP-as-a-principled-framework"><span class="nav-number">3.2.2.</span> <span class="nav-text">Language Understanding Uncertainty: POMDP as a principled framework</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scaling-up-Dialogue-Optimization"><span class="nav-number">3.2.3.</span> <span class="nav-text">scaling up Dialogue Optimization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Natural-language-understanding-and-dialogue-state-tracking"><span class="nav-number">3.3.</span> <span class="nav-text">Natural language understanding and dialogue state tracking</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Language-Understanding"><span class="nav-number">3.3.1.</span> <span class="nav-text">Language Understanding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dialogue-State-Tracking-DST"><span class="nav-number">3.3.2.</span> <span class="nav-text">Dialogue State Tracking(DST)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-RL-for-dialogue-policy-learning"><span class="nav-number">3.4.</span> <span class="nav-text">Deep RL for dialogue policy learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Two-main-classed-of-RL-algorithms"><span class="nav-number">3.4.1.</span> <span class="nav-text">Two main classed of RL algorithms</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Domain-Extension-and-Exploration-BBQ-network"><span class="nav-number">3.4.2.</span> <span class="nav-text">Domain Extension and Exploration(BBQ network)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Composite-task-Dialogues"><span class="nav-number">3.4.3.</span> <span class="nav-text">Composite-task Dialogues</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Decision-theoretic-View-of-Dialogue-Management"><span class="nav-number">3.5.</span> <span class="nav-text">Decision-theoretic View of Dialogue Management</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Hybrid-Code-Networks"><span class="nav-number">3.5.1.</span> <span class="nav-text">Hybrid Code Networks</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Differentiating-KB-Accesses"><span class="nav-number">3.5.2.</span> <span class="nav-text">Differentiating KB Accesses</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#An-E2E-Neural-Dialogue-System"><span class="nav-number">3.5.3.</span> <span class="nav-text">An E2E Neural Dialogue System</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fully-data-driven-conversation-models-and-chatbots"><span class="nav-number">4.</span> <span class="nav-text">Fully data-driven conversation models and chatbots</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Historical-overview"><span class="nav-number">4.1.</span> <span class="nav-text">Historical overview</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Response-retrival-system"><span class="nav-number">4.1.1.</span> <span class="nav-text">Response retrival system</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Response-generation-using-Statistical-Machine-Translation"><span class="nav-number">4.1.2.</span> <span class="nav-text">Response generation using Statistical Machine Translation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#First-neural-response-generation-systems"><span class="nav-number">4.1.3.</span> <span class="nav-text">First neural response generation systems</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#challenges-and-remedies"><span class="nav-number">4.2.</span> <span class="nav-text">challenges and remedies</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Challenge-The-blandness-problem"><span class="nav-number">4.2.1.</span> <span class="nav-text">Challenge: The blandness problem</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Challenge-The-consistency-problem"><span class="nav-number">4.2.2.</span> <span class="nav-text">Challenge: The consistency problem</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Challenge-Long-conversational-context"><span class="nav-number">4.2.3.</span> <span class="nav-text">Challenge: Long conversational context</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Grounded-conversation-models"><span class="nav-number">4.3.</span> <span class="nav-text">Grounded conversation models</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#A-Knowledge-Grounded-Neural-Conversation-Model"><span class="nav-number">4.3.1.</span> <span class="nav-text">A Knowledge-Grounded Neural Conversation Model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Grounded-E2E-Dialogue-Systems"><span class="nav-number">4.3.2.</span> <span class="nav-text">Grounded E2E Dialogue Systems</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue"><span class="nav-number">4.4.</span> <span class="nav-text">Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-and-evaluation"><span class="nav-number">4.5.</span> <span class="nav-text">Data and evaluation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Conversational-datasets-for-social-bots-E2E-dialogue-research"><span class="nav-number">4.5.1.</span> <span class="nav-text">Conversational datasets(for social bots, E2E dialogue research)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation"><span class="nav-number">4.5.2.</span> <span class="nav-text">Evaluating E2E Dialogue Systems via Autumatic evaluation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-importance-of-sample-size"><span class="nav-number">4.5.3.</span> <span class="nav-text">The importance of sample size</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Corpus-level-Correlation"><span class="nav-number">4.5.4.</span> <span class="nav-text">Corpus-level Correlation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chatbot-in-public"><span class="nav-number">4.6.</span> <span class="nav-text">Chatbot in public</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Social-Bots-commercial-systems"><span class="nav-number">4.6.1.</span> <span class="nav-text">Social Bots: commercial systems</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Open-Benchmarks"><span class="nav-number">4.6.2.</span> <span class="nav-text">Open Benchmarks</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhengyuan Zhu</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">博客全站共69.4k字</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a></div>
  <span>　<i class="fa fa-bomb"></i></span>
  <span id="showDays"></span>  




<script>
  var seconds = 1000;
  var minutes = seconds * 60;
  var hours = minutes * 60;
  var days = hours * 24;
  var years = days * 365;
  var birthDay = Date.UTC(2018,07,27,00,00,00); // 这里设置建站时间
  setInterval(function() {
    var today = new Date();
    var todayYear = today.getFullYear();
    var todayMonth = today.getMonth()+1;
    var todayDate = today.getDate();
    var todayHour = today.getHours();
    var todayMinute = today.getMinutes();
    var todaySecond = today.getSeconds();
    var now = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
    var diff = now - birthDay;
    var diffYears = Math.floor(diff/years);
    var diffDays = Math.floor((diff/days)-diffYears*365);
    var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
    var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
    var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
      document.getElementById('showDays').innerHTML="本站已运行 "+diffYears+" 年 "+diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
  }, 1000);
</script>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  <script type="text/javascript" color="255,255,255" opacity='1' zIndex="-2" count="81" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>




  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("lrStmEgU8MjAwlxcSITnS6DR-gzGzoHsz", "iR6jz7gj1mKzrFtB6EqbxmzK");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  


  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.3"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.3"></script>


  
  <script type="text/javascript" src="/js/src/exturl.js?v=5.1.3"></script>


  <script src="/js/src/Aplayer-Controler.js"></script>
<div id="AP-controler"></div>
<script type="text/javascript">
var myapc=new APlayer_Controler({
		APC_dom:$('#AP-controler'),
		aplayer:ap, //此为绑定的aplayer对象
		attach_right:false,
		position:{top:'300px',bottom:''},
		fixed:true,
		btn_width:100,
		btn_height:120,
		img_src:['http://oty1v077k.bkt.clouddn.com/bukagirl.jpg',
				'http://oty1v077k.bkt.clouddn.com/jumpgirl.jpg',
				'http://oty1v077k.bkt.clouddn.com/pentigirl.jpg',
				'http://oty1v077k.bkt.clouddn.com/%E8%90%8C1.gif'],
		img_style:{repeat:'no-repeat',position:'center',size:'contain'},
		ctrls_color:'rgba(173,255,47,0.8)',
		ctrls_hover_color:'rgba(255,140,0,0.7)',
		tips_on:true,
		tips_width:140,
		tips_height:25,
		tips_color:'rgba(255,255,255,0.6)',
		tips_content:{},
		timeout:30
	});
</script>

<!-- 页面点击特效 -->
<!-- <script type="text/javascript" src="/js/src/click-effect.js"></script> -->




<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"sciptFrom":"local","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"superSample":2,"width":300,"height":600,"position":"left","hOffset":0,"vOffset":-150},"mobile":{"show":true,"scale":0.01},"react":{"opacityDefault":0.9,"opacityOnHover":0.9},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
